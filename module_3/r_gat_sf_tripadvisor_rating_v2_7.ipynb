{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "r-gat-sf-tripadvisor-rating-v2-7.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4CcC7yuWbJw"
      },
      "source": [
        "# Predict TripAdvisor Rating\n",
        "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI0A6S6hWbJy"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "GVevQoNjWbJz"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "%matplotlib inline\n",
        "\n",
        "# Загружаем специальный удобный инструмент для разделения датасета:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "import re\n",
        "import datetime\n",
        "from datetime import datetime, timedelta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sQK18_wiWbJ7"
      },
      "source": [
        "# проверка на работу в \"google colab\" или \"локально\"\n",
        "\n",
        "if 'sample_data' in os.listdir():\n",
        "    project_dir = r'/content/drive/My Drive/Colab Notebooks/module_3/'\n",
        "    print('Обнаружена среда выполнения Google Colab.')\n",
        "    print('project_dir =>', project_dir)\n",
        "else:\n",
        "    project_dir = ''\n",
        "    print('НЕ обнаружена среда выполнения Google Colab. Выбран режим локальной работы.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LcfyLlFpWbJ_"
      },
      "source": [
        "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
        "RANDOM_SEED = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc6oZ7I6NaoD"
      },
      "source": [
        "### Функции обработки\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PVd96LNCWbKI"
      },
      "source": [
        "def reviews_word_analyzer(incoming, mode='pos'):\n",
        "    ''' Оценка позитивной\\негативной окраски текстового сообщения.\n",
        "        Проверяется каждое слово на вхождение в список позитивных или негативных словарей.\n",
        "        Возвращается количество найденных вхождений.\n",
        "    '''\n",
        "    word_count = 0\n",
        "    # определяем справочник для проверки вхождения слов   \n",
        "    if type(incoming) is list:\n",
        "        incoming = ','.join(incoming)\n",
        "    if mode == 'pos':\n",
        "        control_list = pos_words\n",
        "    else:\n",
        "        control_list = neg_words\n",
        "    # подсчитываем количество вхождений    \n",
        "    for word in re.findall(r'[a-zA-Z\\-]+', incoming):\n",
        "        if word in control_list:\n",
        "            word_count += 1\n",
        "    return word_count\n",
        "# end function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrgJYzUikD1g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNb40DwKVp-H",
        "scrolled": true
      },
      "source": [
        "def column_content_analysis(column_name_list, column_type='str', more_than = 10):\n",
        "    '''\n",
        "        Функция для определения типовых параметров данных, а также определние \"замусоренности\".\n",
        "        На вход принимает список столбцов датафрейма\n",
        "    '''\n",
        " # проходим циклом по списку колонок    \n",
        "    for column_name in column_name_list:\n",
        "        print('-'*60)\n",
        "        print('|\\t' , 'Отчет по колонке [', column_name, ']', '\\t'*5)\n",
        "        print('-'*60)\n",
        "        row_count = data.shape[0]\n",
        "        if column_name not in data.columns:\n",
        "            print('|  Внимание!!! Указанная колонка не найдена в датасете. \\n')\n",
        "            break\n",
        "\n",
        "        col_count = data[column_name].count()\n",
        "        col_type = data[column_name].dtype\n",
        "        print('|  Тип данных:', col_type) \n",
        "        print('|  Заполнено значений:',  col_count, 'из', row_count)\n",
        "        print('|  Отсутсвующие значения:', row_count - col_count)\n",
        "        print('|  Полнота данных: ', round(col_count / row_count * 100 ,2), '%', sep='')\n",
        "        print('|  Количество уникальных значений:', data[column_name].nunique())\n",
        "\n",
        "        print('|  Значений, встретившихся в столбце более', more_than,'раз:', \n",
        "              (data[column_name].value_counts() > more_than).sum())\n",
        "\n",
        "        if col_type == 'object':\n",
        "            # Количество пробелов в начале в конце строки\n",
        "            print('|  Количество раз пробелы найдены:')\n",
        "            find_list = [len(re.findall(r'^\\s+\\w?', str(x))) for x in data[column_name]]\n",
        "            print('|    в начале строки:', sum(find_list))\n",
        "            \n",
        "            find_list = [len(re.findall(r'\\w?\\s+$', str(x))) for x in data[column_name]]\n",
        "            print('|    в конце  строки:', sum(find_list))\n",
        "            \n",
        "            find_list = [len(re.findall(r'[^\\s\\d\\w]', str(x))) for x in data[column_name]]\n",
        "            print('|  Количество найденных специальных символов:', sum(find_list))\n",
        "        \n",
        "        if col_type in ['int', 'float']:\n",
        "            print('|  Медиана: ', data[column_name].median())\n",
        "            \n",
        "            perc25 = data[column_name].describe().loc['25%']\n",
        "            perc75 = data[column_name].describe().loc['75%']\n",
        "            iqr = perc75 - perc25\n",
        "            range_left = perc25 - 1.5 * iqr\n",
        "            range_right = perc75 + 1.5 * iqr\n",
        "            \n",
        "            # Границы выбросов\n",
        "            print('|  IQR: ', iqr, '; границы выбросов: [', round(range_left, 2), '; ', round(range_right,2),']' , sep='')\n",
        "            out_of_range_left = data[column_name].loc[data[column_name] < range_left]\n",
        "            out_of_range_right = data[column_name].loc[data[column_name] > range_right]\n",
        "            out_of_range = len(out_of_range_left) + len(out_of_range_right)\n",
        "            if out_of_range > 0:\n",
        "                print('|  Данные СОДЕРЖАТ выбросы, количество значений: ', out_of_range)\n",
        "                if len(out_of_range_left) > 0:\n",
        "                    print('|    Слева  от IQR (уникальные):', out_of_range_left.unique())\n",
        "                if len(out_of_range_right) > 0:\n",
        "                    print('|    Справа от IQR (уникальные):', out_of_range_right.unique())\n",
        "         \n",
        "        print('|---\\n|  Все уникальные значения:', data[column_name].unique() , '\\n')\n",
        "\n",
        "\n",
        "    # end function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viVZBCkxWbKL"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc-42parXDYE"
      },
      "source": [
        "# Выведем листинг проектного каталога\n",
        "for dirname, _, filenames in os.walk(project_dir):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "Q7xEPPSEWbKM"
      },
      "source": [
        "\n",
        "df_train = pd.read_csv(project_dir + 'main_task.csv')\n",
        "df_test = pd.read_csv(project_dir + 'kaggle_task.csv')\n",
        "sample_submission = pd.read_csv(project_dir + 'sample_submission.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HaBbN6RjWbKP"
      },
      "source": [
        "# подключаем дополнительные источники - словари\n",
        "\n",
        "negotive = pd.read_csv(project_dir + 'neg_words.txt', names=['neg_word'], encoding='latin-1')\n",
        "positive = pd.read_csv(project_dir + 'positive-words.txt', names=['pos_word'], encoding='latin-1', comment=';')\n",
        "\n",
        "negotive.shape, positive.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wibafZzHWbKU"
      },
      "source": [
        "# словарь негативно окрашенных слов\n",
        "negotive.sample(9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ne1PprtkWbKZ"
      },
      "source": [
        "# подготовим список негативных слов\n",
        "neg_words = negotive['neg_word'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s4SB48FXWbKb"
      },
      "source": [
        "# словарь позитивно окрашенных слов\n",
        "positive.sample(9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d1GqvrFPWbKd"
      },
      "source": [
        "# подготовим список слов с позитивной окраской\n",
        "pos_words = positive['pos_word'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iWrPqtZ7WbKg"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MBzi_r6bWbKj"
      },
      "source": [
        "df_train.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Vfis-1c6WbKl"
      },
      "source": [
        "df_test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6mporFxfWbKo"
      },
      "source": [
        "df_test.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Kcth03zWbKr"
      },
      "source": [
        "sample_submission.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NAfCBwEZWbKt"
      },
      "source": [
        "sample_submission.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RVBhyzCxWbKv"
      },
      "source": [
        "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
        "df_train['sample'] = 1 # помечаем где у нас трейн\n",
        "df_test['sample'] = 0 # помечаем где у нас тест\n",
        "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
        "\n",
        "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7oIM3M_xWbKy"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYFC0a92WbK0"
      },
      "source": [
        "Подробнее по признакам:\n",
        "* City: Город \n",
        "* Cuisine Style: Кухня\n",
        "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
        "* Price Range: Цены в ресторане в 3 категориях\n",
        "* Number of Reviews: Количество отзывов\n",
        "* Reviews: 2 последних отзыва и даты этих отзывов\n",
        "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
        "* ID_TA: ID ресторана в TripAdvisor\n",
        "* Rating: Рейтинг ресторана"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q8cDlapDWbK0"
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFV9zKnxnRUr"
      },
      "source": [
        "## Информация о колонках"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg20hbpgM9LQ"
      },
      "source": [
        "# выведем детальный отчет по анализу данных в колонках\n",
        "\n",
        "column_content_analysis(data.columns, more_than=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgV_87gmWbK6"
      },
      "source": [
        "Как видим, большинство признаков у нас требует очистки и предварительной обработки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XomxtpeWWbK6"
      },
      "source": [
        "## Cleaning and Prepping Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BfjcX5BWbK7"
      },
      "source": [
        "## 1. Обработка NAN \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XFgeErsTWbK7"
      },
      "source": [
        "# возмем столбец Number of Reviews\n",
        "data['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r4RSjZPbWbK9"
      },
      "source": [
        "data['Number_of_Reviews_isNAN']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_n9JvWVPWbK_"
      },
      "source": [
        "# Далее заполняем пропуски 0, вы можете попробовать заполнением средним или средним по городу и тд...\n",
        "data['Number of Reviews'].fillna(0, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGsvtcM0WbLC"
      },
      "source": [
        "# 2. Обработка признаков\n",
        "Посмотрим какие признаки у нас могут быть категориальными."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NmDUeLiRWbLC"
      },
      "source": [
        "data.nunique(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At0loQ8UWbLF"
      },
      "source": [
        "Указанные признаки можно считать категориальными\n",
        "* City\n",
        "* Cuisine Style\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VOVRWNu8WbK4"
      },
      "source": [
        "# посмотрим на один из отзывов\n",
        "data.Reviews[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc4VJ8Iyom4k"
      },
      "source": [
        "Потребуется парсинг и разборе признака. Текстовые отзывы можно обработать на факт эмоционального окраса отзыва. После обрабокти сформировать дополнительные признаки.\n",
        "\n",
        "Даты отзывов можно трансформировать в признак, посчитав длительность между ними, например в минутах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZOmZRYKpLIE"
      },
      "source": [
        "## Кодирование признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eeru_bD-WbLG"
      },
      "source": [
        "Для кодирования категориальных признаков есть множество подходов:\n",
        "* Label Encoding\n",
        "* One-Hot Encoding\n",
        "* Target Encoding\n",
        "* Hashing\n",
        "\n",
        "Выбор кодирования зависит от признака и выбраной модели.\n",
        "Не будем сейчас сильно погружаться в эту тематику, давайте посмотрим лучше пример с One-Hot Encoding:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-DMecHaaWbLG"
      },
      "source": [
        "# для One-Hot Encoding в pandas есть готовая функция - get_dummies\n",
        "data = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_QfpQyiKWbLN"
      },
      "source": [
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWGaBX5pWbLP"
      },
      "source": [
        "## \"Price Range\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_5zgWAqNWbLP"
      },
      "source": [
        "data['Price Range'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYJbpUONWbLT"
      },
      "source": [
        "По описанию 'Price Range' это - Цены в ресторане.  \n",
        "Их можно поставить по возрастанию (значит это не категориальный признак). А это значит, что их можно заменить последовательными числами, например 1,2,3  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GUqWQVPhWbLT"
      },
      "source": [
        "# обработка 'Price Range'\n",
        "\n",
        "# подготовим словарь для конвертации значений\n",
        "price_range_dict = dict(zip(['$$ - $$$', '$', '$$$$'], [500, 5, 5000]))\n",
        "\n",
        "data['Price Range'] = data['Price Range'].replace(to_replace=price_range_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UQn7kmanWbLV"
      },
      "source": [
        "data['Price Range'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YZ_CqUeGWbLY"
      },
      "source": [
        "data.columns[:11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bl327F_pwZK"
      },
      "source": [
        "## \"Cuisine Style\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SGLkssoEWbLb"
      },
      "source": [
        "data['Cuisine Style'] = data['Cuisine Style'].apply(lambda x: re.findall(r\"[^'][\\w\\s]+[^']\", str(x)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oKmOVQPiWbLd"
      },
      "source": [
        "%%time\n",
        "data = pd.get_dummies(data.explode('Cuisine Style'), columns=['Cuisine Style'], prefix='CS', dummy_na=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qg-GixuZWbLf"
      },
      "source": [
        "# data0.sample(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cqhQtYcuWbLh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_14IKLQWbLj"
      },
      "source": [
        "# EDA \n",
        "[Exploratory Data Analysis](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных) - Анализ данных\n",
        "На этом этапе мы строим графики, ищем закономерности, аномалии, выбросы или связи между признаками.\n",
        "В общем цель этого этапа понять, что эти данные могут нам дать и как признаки могут быть взаимосвязаны между собой.\n",
        "Понимание изначальных признаков позволит сгенерировать новые, более сильные и, тем самым, сделать нашу модель лучше.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVt5InfYWbLj"
      },
      "source": [
        "### Посмотрим распределение признака"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gM8bBxmEWbLk"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (10,7)\n",
        "df_train['Ranking'].hist(bins=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8TZT7imWbLm"
      },
      "source": [
        "У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-NjcvC4EWbLn"
      },
      "source": [
        "df_train['City'].value_counts(ascending=True).plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q1X-dojWbLr"
      },
      "source": [
        "А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "afkvNXObWbLr"
      },
      "source": [
        "df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TzNftiRYWbLx"
      },
      "source": [
        "# посмотрим на топ 10 городов\n",
        "for x in (df_train['City'].value_counts())[0:10].index:\n",
        "    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmkwtHOQWbL0"
      },
      "source": [
        "Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA9D9eAjWbL1"
      },
      "source": [
        "### Распределение целевой переменной"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v3X9UX4wWbL1"
      },
      "source": [
        "df_train['Rating'].value_counts(ascending=True).plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RNXyQn7WbL3"
      },
      "source": [
        "### Распределение целевой переменной относительно признака"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PPiSlrAvWbL5"
      },
      "source": [
        "df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-xy9c0HvWbL8"
      },
      "source": [
        "df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLXmKSrTWbL-"
      },
      "source": [
        "### Корреляция признаков\n",
        "На этом графике можно заметить, как признаки связаны между собой и с целевой переменной."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mDRN3muAWbL_"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (15,10)\n",
        "sns.heatmap(data.drop(['sample'], axis=1).corr(),)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPscu_EkWbMB"
      },
      "source": [
        "# Data Preprocessing\n",
        "Для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IHg2pD4vWbMB"
      },
      "source": [
        "# на всякий случай, заново подгружаем данные\n",
        "df_train = pd.read_csv(project_dir + 'main_task.csv')\n",
        "df_test = pd.read_csv(project_dir + 'kaggle_task.csv')\n",
        "df_train['sample'] = 1 # помечаем где у нас трейн\n",
        "df_test['sample'] = 0 # помечаем где у нас тест\n",
        "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
        "\n",
        "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
        "data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vUTJucC5WbML"
      },
      "source": [
        "def preproc_data(df_input):\n",
        "    '''includes several functions to pre-process the predictor data.'''\n",
        "    \n",
        "    df_output = df_input.copy()\n",
        "    \n",
        "    # ################### 1. Предобработка ############################################################## \n",
        "    # убираем не нужные для модели признаки\n",
        "    df_output.drop(['Restaurant_id','ID_TA'], axis = 1, inplace=True)\n",
        "    \n",
        "    \n",
        "    # ################### 2. NAN ############################################################## \n",
        "    # Далее заполняем пропуски\n",
        "    df_output['Number of Reviews'].fillna(0, inplace=True)\n",
        "    # тут ваш код по обработке NAN\n",
        "    df_output['Price Range'].fillna('0', inplace=True)\n",
        "    \n",
        "    # для нулевых значений поставим средние значения по городу\n",
        "    number_of_reviews_mean = df_output.groupby('City')['Number of Reviews'].mean()\n",
        "    df_output['Number of Reviews'] = df_output.apply(lambda row: number_of_reviews_mean[row['City']] if row['Number of Reviews'] == 0 else row['Number of Reviews'], axis=1)\n",
        "    \n",
        "    \n",
        "    # ################### 3. Encoding ############################################################## \n",
        "    # get_dummies\n",
        "    \n",
        "    df_output = pd.get_dummies(df_output, columns=[ 'City',], dummy_na=True)\n",
        "    \n",
        "    price_range_dict = dict(zip(['$$ - $$$', '$', '$$$$', '0'], [500, 5, 5000, 0]))\n",
        "    df_output['Price Range'] = df_output['Price Range'].replace(to_replace=price_range_dict)\n",
        "\n",
        "    df_output['Cuisine Style'] = df_output['Cuisine Style'].apply(lambda x: re.findall(r\"[^'][\\w\\s]+[^']\", str(x)))\n",
        "\n",
        "    df_output = pd.concat([df_output, \n",
        "                 pd.get_dummies(df_output.explode('Cuisine Style')['Cuisine Style'], dummy_na=True)], axis = 1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # ################### 4. Feature Engineering ####################################################\n",
        "    #\n",
        "\n",
        "    df_output['score_pos'] = df_output['Reviews'].apply(lambda x: reviews_word_analyzer(str(x), mode='pos'))\n",
        "\n",
        "    df_output['score_neg'] = df_output['Reviews'].apply(lambda x: reviews_word_analyzer(str(x), mode='neg'))\n",
        "    \n",
        "    \n",
        "    df_output['reviews_data'] = df_output['Reviews'].apply(lambda x: re.findall(r\"\\d\\d\\/\\d\\d\\/\\d{4}\", str(x)) \n",
        "                                                           if len(re.findall(r\"\\d\\d\\/\\d\\d\\/\\d{4}\", str(x))) == 2\n",
        "                                                           else ['01/01/2000', '01/01/2000'])\n",
        "\n",
        "    df_output['reviews_delta'] = df_output['reviews_data'].apply(lambda x: (datetime.timestamp(datetime.strptime(x[0], '%m/%d/%Y')) \n",
        "                                                                    - datetime.timestamp(datetime.strptime(x[1], '%m/%d/%Y')))/60 )\n",
        "    \n",
        "    # ################### 5. Clean #################################################### \n",
        "    # убираем признаки которые еще не успели обработать, \n",
        "    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберем их и удалим\n",
        "    \n",
        "    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n",
        "    df_output.drop(object_columns, axis = 1, inplace=True)\n",
        "    \n",
        "    return df_output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWfk3j4TqXrj"
      },
      "source": [
        "Новые признаки:\n",
        "\n",
        "1.  `score_pos` - числовая оценка положительного окраса отзыва\n",
        "2.  `score_neg` - числовая оценка отрицтельного окраса отзыва\n",
        "3. `reviews_delta` - количество минут между послденим и предпоследним отзывом\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGHL1Zk_WbMT"
      },
      "source": [
        "#### Запускаем и проверяем что получилось"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U_aNOPF1WbMU"
      },
      "source": [
        "df_preproc = preproc_data(data)\n",
        "df_preproc.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yp7k_NKFWbMX"
      },
      "source": [
        "df_preproc.sample(9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mrHbZcPrWbMk"
      },
      "source": [
        "# Теперь выделим тестовую часть\n",
        "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
        "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
        "\n",
        "y = train_data.Rating.values            # наш таргет\n",
        "X = train_data.drop(['Rating'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuAk7BclWbMq"
      },
      "source": [
        "Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
        "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pxP82QDvWbMq"
      },
      "source": [
        "# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n",
        "# выделим 20% данных на валидацию (параметр test_size)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UGroBeQsWbMt"
      },
      "source": [
        "# проверяем\n",
        "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8b-GgXnWbMw"
      },
      "source": [
        "### Model \n",
        "Сам ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RQzz27s6WbMw"
      },
      "source": [
        "# Импортируем необходимые библиотеки:\n",
        "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
        "from sklearn import metrics # инструменты для оценки точности модели"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7TGbf5hLWbMy"
      },
      "source": [
        "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
        "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZbUh2PpGWbM1"
      },
      "source": [
        "%%time\n",
        "# Обучаем модель на тестовом наборе данных\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PSKv2sSgWbM4"
      },
      "source": [
        "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
        "# Предсказанные значения записываем в переменную y_pred\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj4Is0onEaND"
      },
      "source": [
        "# MAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lc-RnxghWbM7"
      },
      "source": [
        "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
        "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
        "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8iyjD48tEL4"
      },
      "source": [
        "*  Исходное значение метрики:\n",
        "> MAE: 0.21240125\n",
        "\n",
        "* Добавлен обработчик пустых значений для количества отзывов. Устанавливает среднее по городу.  Изменение метрики:\n",
        "> MAE: 0.0995425\n",
        "\n",
        "* Добавлена дельта времени между отзывами в минутах.  Изменение метрики:\n",
        "> MAE: 0.089500\n",
        "\n",
        "*  Небольшое изменение логики обработки пустых значений.  Изменение метрики:\n",
        "> MAE: 0.089434\n",
        "\n",
        "* Добавлена оценка отзывов на наличие негативных или позитивных слов. Изменение метрики:\n",
        "> MAE: 0.0875\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gYbQcQUJWbM-"
      },
      "source": [
        "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
        "plt.rcParams['figure.figsize'] = (10,10)\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(15).plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH0QsOD3WbNA"
      },
      "source": [
        "### Submission\n",
        "Готовим Submission на кагл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MVBF03dwWbNA"
      },
      "source": [
        "test_data.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4w_-XDgbWbNC"
      },
      "source": [
        "test_data = test_data.drop(['Rating'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PGEOVV2wWbND"
      },
      "source": [
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O0_oyHCuWbNF"
      },
      "source": [
        "predict_submission = model.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oULaj4jLWbNG"
      },
      "source": [
        "# приведем рейтинг к кратности шага 0.5\n",
        "predict_submission = list(map(lambda x: round(x * 2)/2, predict_submission))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1JpZ7UH9WbNK"
      },
      "source": [
        "# посмотрим что получилось\n",
        "len(predict_submission), predict_submission[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bXwJyjQRWbNM"
      },
      "source": [
        "sample_submission['Rating'] = predict_submission[0:10000]\n",
        "sample_submission.to_csv(project_dir + 'submission.csv', index=False)\n",
        "sample_submission.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT5cEu97WbNO"
      },
      "source": [
        "# Выводы\n",
        "\n",
        "Чтобы улучшить результат:\n",
        "* Обработали и превратили оставшиеся признаки в понятный для машины формат - цифровые признаки.\n",
        "* Придумали, что еще можно извлечь из признаков и расширили набор исходных данных.\n",
        "* Сгенерировать новые признаки.\n",
        "* Подгрузить дополнительные данные - обработка содержрания отзывов на ключевые показатели.\n",
        "* Подобрали состав признаков.\n",
        "* Структурное изменение датафрейма с `11` до `167` столбцов.\n",
        "* Сократили `MAE`: c `0.2124` до `0.0875`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERrMWvTbs8tU"
      },
      "source": [
        "# Спасибо за внимание!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Mjg2sNvg8I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}